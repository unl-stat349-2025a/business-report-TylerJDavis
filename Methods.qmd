---
title: "Methods"
editor: visual
bibliography: references.bib
---

When thinking about how to conduct the analysis on percent chance a bridge collapses in Omaha, NE. The first task was a to find a data set that contained all of the information that we would need, and that was the NTAD National Bridge Inventory. This data set described in the data documentation, allows us to attempt to figure out the main question at had what the percent chance that a bridge will collapse in Omaha, NE. This data set was filtered to contain all bridges in Iowa and Nebraska by the state code variable, it was then filtered again to focus in on the Omaha area. This was done by filter statements in R, using state codes, latitudes, and longitudes. This subset of the NTAD data was then used for the analysis.

```{r}
#| echo: false
#| message: false
#| warning: false
library(tidyverse)
library(dplyr)
library(psych)
library(knitr)

omaha_bridges <- read.csv("omaha_bridges.csv")
library(leaflet)
leaflet(omaha_bridges) %>%
  addTiles() %>%
  addCircleMarkers(
    lng = ~ LONG_017,
    lat = ~ LAT_016,
    radius = 5,
    color = "red",
    popup = ~paste("Bridge ID:", FACILITY_CARRIED_007)
  )
```

This map above shows how the data contains all of the bridges in the Omaha, NE area. This is crucial as our task is limited to this area. The next step in our analysis is to further understand what variables within the data set are useful to us. This decision was made by analyzing the code book and understanding which variables give us key insight into the structure, age, traffic, and condition of the bridges. These variables will hopefully lead us to be able to draw a conclusion that meet our goal of predicting a bridge collapse.

```{r}
#| echo: false
#| message: false
#| warning: false
fil_dat <- omaha_bridges %>%
  select(c(1,2,5,14,21,22,25, 28:29,31:32, 68:77,88,103,107,112,116, 122:125))
library(magrittr)
desc_dat <- data.frame(variable = names(fil_dat),
           classes = sapply(fil_dat, typeof),
           first_values = sapply(fil_dat, function(x) paste0(head(x),  collapse = ", ")),
           row.names = NULL)
kable(desc_dat)
```

This table above shows the variables from the data set that will be used to analyze the data as they describe key components about each bridge. We next analyzed the variables that saw that bridge condition was a variable that describes the overall condition of the bridge, which has rating of "P" for poor, "G" for good, and "F" for fair. Bridge condition rating is determined by, " the lowest rating of National Bridge Inventory (NBI) condition ratings for Item 58 (Deck), Item 59 (Superstructure), Item 60 (Substructure), or Item 62 (Culvert). If the lowest rating is greater than or equal to 7, the bridge is classified as Good; if it is less than or equal to 4, the classification is Poor. Bridges rated 5 or 6 are classified as Fair.", @wesemanRecordingCodingGuide. This allows us to looks at the overall condition of the bridge by looking primarily at one variable.

```{r}
#| echo: false
#| message: false
#| warning: false
library(ggplot2)

ggplot(fil_dat,aes(x = BRIDGE_CONDITION)) + geom_bar() + labs(title ="Bridge Condition") + xlab("Bridge Rating")

```

Here we can see the overall breakdown of how the bridge condition variable is broken down. We now want to take a closer look into what bridges are rated with a condition as "P" or poor.

```{r}
#| echo: false
#| message: false
#| warning: false
fil_dat <- fil_dat %>%
  mutate(across(everything(), ~ ifelse(. == "N", NA, .)))

bridge_cond <- fil_dat %>%
 filter(
   BRIDGE_CONDITION == "P"
 ) %>%
   select(c(1,4,5,6,8,9:21,29,27,23))


leaflet(bridge_cond) %>%
  addTiles() %>%
  addCircleMarkers(
    lng = ~ LONG_017,
    lat = ~ LAT_016,
    radius = 5,
    color = "red",
    popup = ~paste("Bridge ID:", FACILITY_CARRIED_007)
  )
```

This graph above shows us the distribution of bridges across Omaha, NE, that have a bridge condition rating of poor. This gives us a good understanding of the bridges at most risk of collapse right now. Another factor that might play a role on if a bridge collapses would be how much traffic a bridge takes in per day. We then created another subset of data from the bridges that have poor condition, and added that the average daily traffic must be greater than 5000 and that is must have over two lanes. This will give us a good picture of major bridges in Omaha, NE that are at risk of collapse that could impact that most people.

```{r}
#| echo: false
#| message: false
#| warning: false

high_traffic <- bridge_cond %>%
  filter (
    ADT_029 > 5000 & TRAFFIC_LANES_ON_028A > 2
  )
leaflet(high_traffic) %>%
  addTiles() %>%
  addCircleMarkers(
    lng = ~ LONG_017,
    lat = ~ LAT_016,
    radius = 5,
    color = "red",
    popup = ~paste("Bridge ID:", FACILITY_CARRIED_007)
  )
```

This graph above show us the distributed of bridges with a poor condition that undergo high traffic scenarios each day. These bridges could possibly be at higher risk for collapse due to the increase of traffic.

Statistical analysis was then conducted, first by analyzing the descriptive statistics of both the bridge condition subset and the high traffic subset. This was then extended by finding the percent of bridges that are at a poor condition and poor condition with high traffic respectively. This gave us a basic understanding of what the overall condition was currently. We then had to create a method of prediction, which was done by fitting a linear model. The missing values in the data set were a concern which lead to imputation methods being used by way of the "VIM" package in R. This then allowed us to analyze the data using a linear model creating a method of prediction of when a bridge would collapse in Omaha, NE.
