[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Evaluation of ",
    "section": "",
    "text": "Preface\nYou are a data scientist for a mid-sized business, in a small group of 3-4 data scientists. You’ve been tasked with creating a report evaluating a scenario for your business. Your colleagues will also be evaluating the same scenario, and your reports will be used in aggregate to determine a consensus (or lack thereof) on the company’s action. The reports will also be used to inform downsizing that is rumored to be coming - you want to ensure your report is better than your peers so that you aren’t as easy to cut.\nYou may talk to your peers who are assigned the same scenario, but you do not want to collaborate too closely, lest you both become targets of the rumored layoffs.\n\nI’ve scaffolded this report for you to make this process easier - as we talk about different sections of a report in class and read about how to create similar sections, you will practice by writing the equivalent section of your report.\nThe basic steps for this task are as follows:\n\nIdentify the research question from the business question\nIdentify data set(s) which are (1) publicly available (you don’t have a budget to pay for private data) and (2) relevant to your task\n\n(HW Week 6) Document your data sets in draft-data-doc.qmd\n\nConduct a statistical analysis to support your answer to your research and business questions\n\nWrite a methods section for your business report corresponding to your statistical analysis\n(HW Week 9) Draft of results section of business report with relevant graphics/visual aids in draft-results.qmd\n\nWrite your report\n\n(HW Week 10) Draft of Intro/Conclusion sections in draft-intro-conclusions.qmd\n(HW Week 11) Draft of Executive summary section in draft-exec-summary.qmd\n\nRevise your report\n\n(HW Week 12 – not turned in) Revise your report\n(HW Week 13) - Rough draft of report due. Create one or more qmd files for your report (you can overwrite or delete intro.qmd and summary.qmd), include the names of each file (in order) in _quarto.yml. You should use references (edit references.bib and use pandoc citations). Make sure your report compiles and looks reasonable in both html and pdf.\nDevelop a presentation to go along with your report (Week 13). Create slides for your report using quarto.\n\nPeer revise reports\n\nPeer revise reports\n(HW Week 14) - Make edits to your report from comments received from peer review\n\nFinal report & presentation due",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\n“National Bridge Inventory (NBI).” n.d. https://tvar-hub-usdot.hub.arcgis.com/pages/national-bridge-inventory.\n\n\nWeseman, William A. n.d. “Recording and Coding Guide.”",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "draft-data-doc.html",
    "href": "draft-data-doc.html",
    "title": "Appendix A — Draft: Data Documentation",
    "section": "",
    "text": "Overview:\nThe data that I will be using is from the Department of transportation. This data set is the national bridge inventory collected annually by the DOT. This data was updated on 09-30-2024. This data provides information about all bridges that are on public roads and span over 20 feet across the United States. It contains information about bridge structure, bridge location, bridge rating, along with many other data points. I will be focusing on bridge location, bridge rating, along with daily traffic load.\nDescription listed on website:\n“The National Bridge Inventory details bridges on public roads that include interstate highways, U.S. highways, state and county roads, and publicly accessible bridges located on Federal and Tribal lands. The database includes the location, description, classification, and condition of each bridge. The condition of the structural and bridge management elements of each bridge are cataloged for all bridges on the National Highway System (NHS).\nThe NBI is published annually but its publication location varies. The 2024 (most recent) NBI is published with a map viewer as part of the Bureau of Transportation Statistics National Transportation Atlas Database. The data set is also published through FHWA’s Bridges & Structures site.\nThe National Bridge Inventory can support resilience analysis and detour planning efforts. It provides bridge location, design load and clearance, roadway geometry, rating, posting and structural evaluations, number of lanes, traffic counts, among other variables.” “National Bridge Inventory (NBI)” (n.d.)\nDetailed information:\nThis data is located on a csv file in excel. It contains 116 variables describing various aspects of bridges. I will be focusing my analysis on variables 1,4,5,21, 28-29, 57 - 67,109,113-115. These variables and all information regarding analysis and coding can be found in the code book, Weseman (n.d.).\nProcess:\nThis data will be used to analyze the question regarding the probability that a bridge will collapse in Omaha, NE. This is the reason certain variables will be analyzed and others will not be as much of a factor. The factors that I will use to make this decision will be location of bridge, amount of lanes, amount of traffic, bridge ratings, daily truck traffic, etc. All of this information and more can be found on the NBI website and data set.\n\n\n\n\n“National Bridge Inventory (NBI).” n.d. https://tvar-hub-usdot.hub.arcgis.com/pages/national-bridge-inventory.\n\n\nWeseman, William A. n.d. “Recording and Coding Guide.”",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Draft: Data Documentation</span>"
    ]
  },
  {
    "objectID": "draft-results.html",
    "href": "draft-results.html",
    "title": "Appendix B — Draft: Results",
    "section": "",
    "text": "The data set that was used to conduct the analysis on percent chance a bridge collapses in Omaha, NE was the NTAD National Bridge Inventory,. This data set was filtered to contain all bridges in Iowa and Nebraska, it was then filtered again to focus in on the Omaha area. This was done by filter statements in R, using state codes, latitudes, and longitudes.\n\ndata &lt;- read.csv(\"NTAD_National_Bridge_Inventory.csv\")\n\nWarning in file(file, \"rt\"): cannot open file\n'NTAD_National_Bridge_Inventory.csv': No such file or directory\n\n\nError in file(file, \"rt\"): cannot open the connection\n\ncols &lt;- data.frame(colnames(data))\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ ggplot2   3.5.1     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.4     ✔ tidyr     1.3.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nnew_dat &lt;- data %&gt;%\n  filter(!is.na(STATE_CODE_001) & as.numeric(STATE_CODE_001) %in% c(19, 31))\n\nError in UseMethod(\"filter\"): no applicable method for 'filter' applied to an object of class \"function\"\n\n# Define bounding box\nlat_min &lt;- 41.0\nlat_max &lt;- 41.5\nlon_min &lt;- 96.2\nlon_max &lt;- 95.8\n\nnew_dat$LAT_016 &lt;- as.numeric(new_dat$LAT_016) / 1e6\n\nError in eval(expr, envir, enclos): object 'new_dat' not found\n\nnew_dat$LONG_017 &lt;- as.numeric(new_dat$LONG_017) / 1e6\n\nError in eval(expr, envir, enclos): object 'new_dat' not found\n\n# Filter the dataset\nomaha_bridges &lt;- new_dat %&gt;%\n  filter(LAT_016 &gt;= lat_min & LAT_016 &lt;= lat_max &\n           LONG_017 &gt;= lon_max & LONG_017 &lt;= lon_min)\n\nError in eval(expr, envir, enclos): object 'new_dat' not found\n\nfil_dat &lt;- omaha_bridges %&gt;%\n  select(c(1,2,5,15,21,25, 28:29,31:32, 68:77,88,103,107,112,116, 122:125))\n\nError in eval(expr, envir, enclos): object 'omaha_bridges' not found\n\ncol &lt;- data.frame(colnames(fil_dat))\n\nError in eval(expr, envir, enclos): object 'fil_dat' not found\n\nfil_dat &lt;- fil_dat %&gt;%\n  mutate(across(everything(), ~ ifelse(. == \"N\", NA, .)))\n\nError in eval(expr, envir, enclos): object 'fil_dat' not found\n\nfiltered &lt;- fil_dat %&gt;%\n  # Group by OBJECTID first\n  group_by(OBJECTID) %&gt;%\n  summarise(\n    avg_rate = mean(\n      c(\n        as.numeric(DECK_COND_058), \n        as.numeric(SUPERSTRUCTURE_COND_059), \n        as.numeric(SUBSTRUCTURE_COND_060),\n        as.numeric(CULVERT_COND_062),\n        as.numeric(CHANNEL_COND_061),\n        as.numeric(STRUCTURAL_EVAL_067)\n      ), \n      na.rm = TRUE\n    ),\n    \n    avg_inv_op = mean(\n      c(as.numeric(OPERATING_RATING_064), as.numeric(INVENTORY_RATING_066)),\n      na.rm = TRUE\n    ),\n    avg_traffic = ADT_029,\n    percent_truck = PERCENT_ADT_TRUCK_109,\n  )\n\nError in eval(expr, envir, enclos): object 'fil_dat' not found\n\n    groups = \"drop\"  # Drops the grouping after summarizing\n  \n\n\nlibrary(psych)\n\n\nAttaching package: 'psych'\n\nThe following objects are masked from 'package:ggplot2':\n\n    %+%, alpha\n\ndescribe(filtered)\n\nError in eval(expr, envir, enclos): object 'filtered' not found\n\n\nHere we are given a summary of the data and each variable and some descriptions attached. This data was then used to break down which bridges have the highest chance of collapsing in Omaha, NE. The criteria for collapsing was based on a variety of factors in the data set that have been filtered in R. This filtering allowed me to see which bridges have the lowest quality structure, maintenance, and most traffic.\n\nhigh_risk_bridges &lt;- filtered %&gt;%\n  filter(\n    avg_rate &lt; 6 &\n    avg_inv_op &lt; 50\n  )\n\nError in eval(expr, envir, enclos): object 'filtered' not found\n\ncollapse &lt;- filtered%&gt;%\n  filter(\n    avg_rate &lt;5 &\n      avg_inv_op &lt; 45 &\n      avg_traffic &gt; 100\n    \n  )\n\nError in eval(expr, envir, enclos): object 'filtered' not found\n\ncollapse_now &lt;- filtered %&gt;%\n  filter(\n    avg_rate &lt; 4.5 &\n      avg_inv_op &lt; 30 &\n      avg_traffic &gt; 150 &\n      percent_truck &gt; 10\n  )\n\nError in eval(expr, envir, enclos): object 'filtered' not found\n\nDo_not_drive &lt;- filtered %&gt;%\n  filter(\n    avg_rate &lt;4 &\n      avg_inv_op &lt; 25\n  )\n\nError in eval(expr, envir, enclos): object 'filtered' not found\n\nCasualties &lt;- filtered %&gt;%\n  filter(\n    avg_rate &lt; 6 &\n    avg_inv_op &lt; 50 &\n    avg_traffic &gt; 1000 &\n      percent_truck &gt; 10\n  )\n\nError in eval(expr, envir, enclos): object 'filtered' not found\n\npercents &lt;- data.frame(\n  \"high risk bridges\" = nrow(high_risk_bridges)/nrow(fil_dat),\n  \"Could collapse\" = nrow(collapse)/nrow(fil_dat),\n  \"collapsing soon\" = nrow(collapse_now)/nrow(fil_dat)\n)\n\nError in eval(expr, envir, enclos): object 'high_risk_bridges' not found\n\nrow.names(percents)[row.names(percents) == \"1\"] &lt;- \"Proportion of Bridges at Risk of Collapse\"\n\nError: object 'percents' not found\n\ntable &lt;- t(percents)\n\nError in eval(expr, envir, enclos): object 'percents' not found\n\nprint(table)\n\nfunction (..., exclude = if (useNA == \"no\") c(NA, NaN), useNA = c(\"no\", \n    \"ifany\", \"always\"), dnn = list.names(...), deparse.level = 1) \n{\n    list.names &lt;- function(...) {\n        l &lt;- as.list(substitute(list(...)))[-1L]\n        if (length(l) == 1L && is.list(..1) && !is.null(nm &lt;- names(..1))) \n            return(nm)\n        nm &lt;- names(l)\n        fixup &lt;- if (is.null(nm)) \n            seq_along(l)\n        else nm == \"\"\n        dep &lt;- vapply(l[fixup], function(x) switch(deparse.level + \n            1, \"\", if (is.symbol(x)) as.character(x) else \"\", \n            deparse(x, nlines = 1)[1L]), \"\")\n        if (is.null(nm)) \n            dep\n        else {\n            nm[fixup] &lt;- dep\n            nm\n        }\n    }\n    miss.use &lt;- missing(useNA)\n    miss.exc &lt;- missing(exclude)\n    useNA &lt;- if (miss.use && !miss.exc && !match(NA, exclude, \n        nomatch = 0L)) \n        \"ifany\"\n    else match.arg(useNA)\n    doNA &lt;- useNA != \"no\"\n    if (!miss.use && !miss.exc && doNA && match(NA, exclude, \n        nomatch = 0L)) \n        warning(\"'exclude' containing NA and 'useNA' != \\\"no\\\"' are a bit contradicting\")\n    args &lt;- list(...)\n    if (length(args) == 1L && is.list(args[[1L]])) {\n        args &lt;- args[[1L]]\n        if (length(dnn) != length(args)) \n            dnn &lt;- paste(dnn[1L], seq_along(args), sep = \".\")\n    }\n    if (!length(args)) \n        stop(\"nothing to tabulate\")\n    bin &lt;- 0L\n    lens &lt;- NULL\n    dims &lt;- integer()\n    pd &lt;- 1L\n    dn &lt;- NULL\n    for (a in args) {\n        if (is.null(lens)) \n            lens &lt;- length(a)\n        else if (length(a) != lens) \n            stop(\"all arguments must have the same length\")\n        fact.a &lt;- is.factor(a)\n        if (doNA) \n            aNA &lt;- anyNA(a)\n        if (!fact.a) {\n            a0 &lt;- a\n            op &lt;- options(warn = 2)\n            on.exit(options(op))\n            a &lt;- factor(a, exclude = exclude)\n            options(op)\n        }\n        add.na &lt;- doNA\n        if (add.na) {\n            ifany &lt;- (useNA == \"ifany\")\n            anNAc &lt;- anyNA(a)\n            add.na &lt;- if (!ifany || anNAc) {\n                ll &lt;- levels(a)\n                if (add.ll &lt;- !anyNA(ll)) {\n                  ll &lt;- c(ll, NA)\n                  TRUE\n                }\n                else if (!ifany && !anNAc) \n                  FALSE\n                else TRUE\n            }\n            else FALSE\n        }\n        if (add.na) \n            a &lt;- factor(a, levels = ll, exclude = NULL)\n        else ll &lt;- levels(a)\n        a &lt;- as.integer(a)\n        if (fact.a && !miss.exc) {\n            ll &lt;- ll[keep &lt;- which(match(ll, exclude, nomatch = 0L) == \n                0L)]\n            a &lt;- match(a, keep)\n        }\n        else if (!fact.a && add.na) {\n            if (ifany && !aNA && add.ll) {\n                ll &lt;- ll[!is.na(ll)]\n                is.na(a) &lt;- match(a0, c(exclude, NA), nomatch = 0L) &gt; \n                  0L\n            }\n            else {\n                is.na(a) &lt;- match(a0, exclude, nomatch = 0L) &gt; \n                  0L\n            }\n        }\n        nl &lt;- length(ll)\n        dims &lt;- c(dims, nl)\n        if (prod(dims) &gt; .Machine$integer.max) \n            stop(\"attempt to make a table with &gt;= 2^31 elements\")\n        dn &lt;- c(dn, list(ll))\n        bin &lt;- bin + pd * (a - 1L)\n        pd &lt;- pd * nl\n    }\n    names(dn) &lt;- dnn\n    bin &lt;- bin[!is.na(bin)]\n    if (length(bin)) \n        bin &lt;- bin + 1L\n    y &lt;- array(tabulate(bin, pd), dims, dimnames = dn)\n    class(y) &lt;- \"table\"\n    y\n}\n&lt;bytecode: 0x562bdaa76d58&gt;\n&lt;environment: namespace:base&gt;\n\n\nWe can see from this table that we have four different categories; high risk, collapse, collapsing soon, and casualties. This four groups were created to see the proportion of bridges that were in the worst state. The high risk category being the lowest risk of collapse and collapsing soon being the highest risk of collapse. We can see from these results that we have a 20% chance of driving on a high risk bridge in Omaha, NE. Along with that we have a 2.4% chance of driving on bridge that could collapse. Finally we have a .15% chance of being on a bridge that could collapse in the near future. This is just a rating system created by me so that we can estimate the proportion of bridges that are at risk of collapse based on traffic data and structural ratings. We were also able to find out some information on the proportion of bridges at high risk of collapse but with the most casualties\n\nCasualties &lt;- filtered %&gt;%\n  filter(\n    avg_rate &lt; 6 &\n    avg_inv_op &lt; 50 &\n    avg_traffic &gt; 1000 &\n      percent_truck &gt; 10\n  )\n\nError in eval(expr, envir, enclos): object 'filtered' not found\n\ndescribe(Casualties)\n\nError in eval(expr, envir, enclos): object 'Casualties' not found\n\n\nThese bridges are at risk of collapse and they also have the highest traffic flow among at risk bridges. These bridges are further at risk due to the fact that the mean percentage of truck traffic is 26% which is very high compared to most bridges in Omaha, NE. F",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Draft: Results</span>"
    ]
  }
]